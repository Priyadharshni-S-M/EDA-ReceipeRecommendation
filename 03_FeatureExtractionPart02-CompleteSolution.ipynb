{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e71f2dc",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a40ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e6d1f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Basics\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b16e5a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-87-194.ec2.internal:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f022e649050>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93738952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyarrow==1.0.0 in ./.local/lib/python3.7/site-packages (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.14 in ./.local/lib/python3.7/site-packages (from pyarrow==1.0.0) (1.14.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: plotly==5.5.0 in ./.local/lib/python3.7/site-packages (5.5.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in ./.local/lib/python3.7/site-packages (from plotly==5.5.0) (8.1.0)\n",
      "Requirement already satisfied: six in ./.local/lib/python3.7/site-packages (from plotly==5.5.0) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas==0.25.1 in ./.local/lib/python3.7/site-packages (0.25.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in ./.local/lib/python3.7/site-packages (from pandas==0.25.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in ./.local/lib/python3.7/site-packages (from pandas==0.25.1) (2022.6)\n",
      "Requirement already satisfied: numpy>=1.13.3 in ./.local/lib/python3.7/site-packages (from pandas==0.25.1) (1.14.5)\n",
      "Requirement already satisfied: six>=1.5 in ./.local/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas==0.25.1) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.14.5 in ./.local/lib/python3.7/site-packages (1.14.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib==3.1.1 in ./.local/lib/python3.7/site-packages (3.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.7/site-packages (from matplotlib==3.1.1) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in ./.local/lib/python3.7/site-packages (from matplotlib==3.1.1) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.11 in ./.local/lib/python3.7/site-packages (from matplotlib==3.1.1) (1.14.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in ./.local/lib/python3.7/site-packages (from matplotlib==3.1.1) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.local/lib/python3.7/site-packages (from matplotlib==3.1.1) (1.4.4)\n",
      "Requirement already satisfied: typing-extensions in ./.local/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib==3.1.1) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.local/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib==3.1.1) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow==1.0.0\n",
    "!pip install plotly==5.5.0\n",
    "!pip install pandas==0.25.1\n",
    "!pip install numpy==1.14.5\n",
    "!pip install matplotlib==3.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccbec7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this everytime you create a new spark instance. \n",
    "\n",
    "# spark.sparkContext.install_pypi_package(\"plotly==5.5.0\")\n",
    "# spark.sparkContext.install_pypi_package(\"pandas==0.25.1\")\n",
    "# spark.sparkContext.install_pypi_package(\"numpy==1.14.5\")\n",
    "# spark.sparkContext.install_pypi_package(\"matplotlib==3.1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cea1e671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Import for typecasting columns\n",
    "from pyspark.sql.types import IntegerType,BooleanType,DateType,FloatType,StringType\n",
    "from pyspark.sql.types import ArrayType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b75577",
   "metadata": {},
   "source": [
    "## Defining Custom Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "515ff4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantiles(df, col_name, quantiles_list = [0.01, 0.25, 0.5, 0.75, 0.99]):\n",
    "    \"\"\"\n",
    "    Takes a numerical column and returns column values at requested quantiles\n",
    "\n",
    "    Inputs \n",
    "    Argument 1: Dataframe\n",
    "    Argument 2: Name of the column\n",
    "    Argument 3: A list of quantiles you want to find. Default value [0.01, 0.25, 0.5, 0.75, 0.99]\n",
    "\n",
    "    Output \n",
    "    Returns a dictionary with quantiles as keys and column quantile values as values \n",
    "    \"\"\"\n",
    "    # Get min, max and quantile values for given column\n",
    "    min_val = df.agg(F.min(col_name)).first()[0]\n",
    "    max_val = df.agg(F.max(col_name)).first()[0]\n",
    "    quantiles_vals = df.approxQuantile(col_name,\n",
    "                                       quantiles_list,\n",
    "                                       0)\n",
    "  \n",
    "    # Store min, quantiles and max in output dict, sequentially\n",
    "    quantiles_dict = {0.0:min_val}\n",
    "    quantiles_dict.update(dict(zip(quantiles_list, quantiles_vals)))\n",
    "    quantiles_dict.update({1.0:max_val})\n",
    "    return(quantiles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca215059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bucketwise_statistics (summary, bucketizer):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe and a bucketizer object and plots the summary statistics for each bucket in the dataframe. \n",
    "  \n",
    "    Inputs\n",
    "    Argument 1: Pandas dataframe obtained from bucket_col_print_summary function \n",
    "    Argument 2: Bucketizer object obtained from bucket_col_print_summary function\n",
    "  \n",
    "    Output\n",
    "    Displays a plot of bucketwise average ratings nunber of ratings of a parameter.   \n",
    "    \"\"\"\n",
    "    # Creating bucket labels from splits\n",
    "    classlist = bucketizer.getSplits()\n",
    "    number_of_classes = len(classlist) - 1\n",
    "\n",
    "    class_labels = []\n",
    "    hover_labels = []\n",
    "    for i in range (number_of_classes):\n",
    "        hover_labels.append(str(classlist[i])+\"-\"+str(classlist[i+1]) +\" (Bucket name: \"+ str(int(i)) +\")\"  )\n",
    "        class_labels.append(str(classlist[i])+\"-\"+str(classlist[i+1]) )\n",
    "  \n",
    "    summary[\"Scaled_number\"] = (summary[\"n_ratings\"]-summary[\"n_ratings\"].min())/(summary[\"n_ratings\"].max()-summary[\"n_ratings\"].min()) + 1.5\n",
    "    summary['Bucket_Names'] = class_labels\n",
    "  \n",
    "    # making plot\n",
    "    x = summary[\"Bucket_Names\"]\n",
    "    y1 = summary[\"avg_rating\"]\n",
    "    y2 = summary[\"n_ratings\"]\n",
    "    err = summary[\"stddev_rating\"]  \n",
    "\n",
    "    # Plot scatter here\n",
    "    plt.rcParams[\"figure.figsize\"] = [summary.shape[0]+2, 6.0]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    bar = ax1.bar(x, y1, color = \"#262261\")\n",
    "    ax1.errorbar(x, y1, yerr=err, fmt=\"o\", color=\"#EE4036\")\n",
    "    ax1.set(ylim=(0, 7))\n",
    "  \n",
    "    #ax1.bar_label(bar , fmt='%.2f', label_type='edge')  \n",
    "    def barlabel(x_list,y_list):\n",
    "        for i in range(len(x_list)):\n",
    "            ax1.text(i,y_list[i] + 0.2,y_list[i], ha = 'center',\n",
    "  \t\t\t         fontdict=dict(size=10),\n",
    "  \t\t\t         bbox=dict(facecolor='#262261', alpha=0.2)         \n",
    "  \t\t\t        )\n",
    "    barlabel(summary[\"Bucket_Names\"].tolist() ,summary[\"avg_rating\"].round(2).tolist())\n",
    "  \n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.scatter(x, y2, s=summary[\"Scaled_number\"]*500, c = '#FAAF40')  \n",
    "    ax2.set(ylim=(0, summary[\"n_ratings\"].max()*1.15))\n",
    "    def scatterlabel(x_list,y_list):\n",
    "  \t    for i in range(len(x_list)):\n",
    "  \t\t    ax2.text(i,y_list[i] + 15000,y_list[i], ha = 'center',\n",
    "  \t\t\t\t\t fontdict=dict(size=10),\n",
    "                     bbox=dict(facecolor='#FAAF40', alpha=0.5)\n",
    "  \t\t\t\t\t)\n",
    "    scatterlabel(summary[\"Bucket_Names\"].tolist() ,summary[\"n_ratings\"].tolist())\n",
    "  \n",
    "    # giving labels to the axises\n",
    "    ax1.set_xlabel(bucketizer.getOutputCol(), fontdict=dict(size=14)) \n",
    "    ax1.set_ylabel(\"Average Ratings\",fontdict=dict(size=14))\n",
    "  \n",
    "    # secondary y-axis label\n",
    "    ax2.set_ylabel('Number of Ratings',fontdict=dict(size=14))\n",
    "  \n",
    "    #plot Title\n",
    "    plt.title('Bucketwise average ratings and number of ratings for \\n'+bucketizer.getInputCol(), \n",
    "              fontdict=dict(size=14)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2da73721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket_col_print_summary(df, splits, inputCol, outputCol):\n",
    "    \"\"\"\n",
    "    Given a numerical column in a data frame, adds a bucketized version of the column to the data frame, according to splits provided.\n",
    "    Also prints a summary of ratings seen in each bucket made.\n",
    "\n",
    "    Inputs \n",
    "    Argument 1: Data Frame \n",
    "    Argument 2: Values at which the column will be split\n",
    "    Argument 3: Name of the input column (numerical column)\n",
    "    Argument 4: Name of the output column (bucketized numerical column)\n",
    "\n",
    "    Output: \n",
    "    1) New dataframe with the output column added\n",
    "    2) Bucketizer object trained from the input column \n",
    "    3) Pandas dataframe with summary statistics for ratings seen in buckets of the output column\n",
    "    Also plots summary statistics for ratings seen in buckets of the output column\n",
    "    \"\"\"\n",
    "\n",
    "    # Dropping bucket if it already exists\n",
    "    if outputCol in df.columns:\n",
    "        df = df.drop(outputCol)\n",
    "\n",
    "    # Training bucketizer\n",
    "    bucketizer = Bucketizer(splits = splits,\n",
    "                            inputCol  = inputCol,\n",
    "                            outputCol = outputCol)\n",
    "    \n",
    "    df = bucketizer.setHandleInvalid(\"keep\").transform(df)\n",
    "\n",
    "    # Printing meta information on buckets created\n",
    "    print(\"Added bucketized column {}\".format(outputCol))\n",
    "    print(\"\")\n",
    "    print(\"Bucketing done for split definition: {}\".format(splits))\n",
    "    print(\"\")  \n",
    "    print(\"Printing summary statistics for ratings in buckets below:\")\n",
    "\n",
    "    # Creating a summary statistics dataframe and passing it to the plotting function\n",
    "    summary =  (df\n",
    "                .groupBy(outputCol)\n",
    "                .agg(F.avg('rating').alias('avg_rating'),\n",
    "                     F.stddev('rating').alias('stddev_rating'),\n",
    "                     F.count('rating').alias('n_ratings'))\n",
    "                .sort(outputCol)\n",
    "                .toPandas())\n",
    "  \n",
    "    plot_bucketwise_statistics(summary,bucketizer)\n",
    "  \n",
    "    return df, bucketizer, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71bd221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_distribution_summary(df, col_name):\n",
    "    \"\"\"\n",
    "    Takes a column in a data frame and prints the summary statistics (average, standard deviation, count and distinct count) for all unique values in that column.\n",
    "  \n",
    "    Inputs \n",
    "    Argument 1: Dataframe \n",
    "    Argument 2: Name of the column\n",
    "  \n",
    "    Output\n",
    "    Returns nothing \n",
    "    Prints a Dataframe with summary statistics\n",
    "    \"\"\"\n",
    "    print(df\n",
    "          .groupBy(col_name)\n",
    "          .agg(F.avg('rating').alias('avg_rating'),\n",
    "               F.stddev('rating').alias('stddev_rating'),\n",
    "               F.count('rating').alias('n_ratings'),\n",
    "               F.countDistinct('id').alias('n_recipes'))\n",
    "          .sort(F.col(col_name).asc())\n",
    "          .show(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79011c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_items_satisfying_condition (df, condition, aggregation_level = \"recipe\"):\n",
    "    \"\"\"\n",
    "    Given a condition, find the number of recipes / reviews that match the condition.\n",
    "    Also calculates the percentage of such recipes / reviews as a percentage of all recipes / reviews.\n",
    "  \n",
    "    Inputs \n",
    "    Argument 1: Dataframe \n",
    "    Argument 2: Logical expression describing a condition, string type. eg: \"minutes == 0\"\n",
    "    Argument 3: Aggregation level for determining \"items\", either  \"recipe\" or \"review\". Default value == \"recipe\"\n",
    "  \n",
    "    Output: Returns no object.\n",
    "    Prints the following:\n",
    "    1) Number of recipes / reviews that satisfy the condition\n",
    "    2) Total number of recipes / reviews in the dataframe\n",
    "    3) Percentage of recipes / reviews that satisfy the condition\n",
    "    \"\"\"\n",
    "    # Find out num rows satisfying the condition\n",
    "    if aggregation_level == \"recipe\": \n",
    "        number_of_rows_satisfying_condition = (df\n",
    "                                             .filter(condition)\n",
    "                                             .agg(F.countDistinct(\"id\"))).first()[0]\n",
    "      \n",
    "        n_rows_total = (df.agg(F.countDistinct(\"id\"))).first()[0]\n",
    "    if aggregation_level == \"review\":\n",
    "        number_of_rows_satisfying_condition = (df\n",
    "                                             .filter(condition)\n",
    "                                             .agg(F.countDistinct(\"id\",\"user_id\"))).first()[0]\n",
    "        n_rows_total = (df.agg(F.countDistinct(\"id\",\"user_id\"))).first()[0]\n",
    "  \n",
    "    # Find out % rows satisfying the conditon and print a properly formatted output\n",
    "    perc_rows = round(number_of_rows_satisfying_condition * 100/ n_rows_total, 2)\n",
    "    print('Condition String                   : \"{}\"'.format(condition))\n",
    "    print(\"Num {}s Satisfying Condition   : {} [{}%]\".format(aggregation_level.title(), number_of_rows_satisfying_condition, perc_rows))\n",
    "    print(\"Total Num {}s                  : {}\".format(aggregation_level.title(), n_rows_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ec89e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_OHE_columns (df, n_name_list):\n",
    "    \"\"\"\n",
    "    Given a list of tags, creates one hot encoded columns for each tag. \n",
    "  \n",
    "    Input\n",
    "    Argument 1: Dataframe in which the function will add the new columns\n",
    "    Argument 2: list of tags\n",
    "  \n",
    "    Output\n",
    "    Prints the names of columns that have been added \n",
    "    Returns the modified dataframe \n",
    "    \"\"\"\n",
    "    for name in n_name_list:\n",
    "        df = (df.withColumn(\"has_tag_\"+name, F.when(F.array_contains(df.tags, name), 1).otherwise(0)))\n",
    "        print (\"added column: has_tag_\"+name)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f974fc0",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6716e7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "interaction_level_df = spark.read.parquet(\"interaction_level_df_postEDA.parquet\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ba87c0",
   "metadata": {},
   "source": [
    "## Adding user level average features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54e70465",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = Window.partitionBy(\"user_id\")\n",
    "\n",
    "interaction_level_df = (interaction_level_df\n",
    "                        .withColumn(\"user_avg_rating\",\n",
    "                                    F.avg(F.col(\"rating\")).over(partition))\n",
    "                        .withColumn(\"user_n_ratings\",\n",
    "                                    F.count(F.col(\"rating\")).over(partition))\n",
    "                        .withColumn(\"user_avg_years_betwn_review_and_submission\",\n",
    "                                    F.avg(F.col(\"years_since_submission_on_review_date\")).over(partition))\n",
    "                        .withColumn(\"user_avg_prep_time_recipes_reviewed\",\n",
    "                                    F.avg(F.col(\"minutes\")).over(partition))\n",
    "                        .withColumn(\"user_avg_n_steps_recipes_reviewed\",\n",
    "                                    F.avg(F.col(\"n_steps\")).over(partition))\n",
    "                        .withColumn(\"user_avg_n_ingredients_recipes_reviewed\",\n",
    "                                    F.avg(F.col(\"n_ingredients\")).over(partition)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ab88a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrition_cols = ['calories',\n",
    "                  'total_fat_per_100_cal',\n",
    "                  'sugar_per_100_cal',\n",
    "                  'sodium_per_100_cal',\n",
    "                  'protein_per_100_cal',\n",
    "                  'saturated_fat_per_100_cal',\n",
    "                  'carbohydrates_per_100_cal']\n",
    "\n",
    "for nutri_col in nutrition_cols:\n",
    "    interaction_level_df = (interaction_level_df\n",
    "                            .withColumn(\"user_avg_{}_recipes_reviewed\".format(nutri_col),\n",
    "                                        F.avg(F.col(nutri_col)).over(partition)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12589059",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Code check cell\n",
    "# Do not edit cells with assert commands\n",
    "# If an error is shown after running this cell, please recheck your code. \n",
    "\n",
    "assert(round(interaction_level_df.filter('user_id == 601529').select('user_avg_rating').first()[0], 2) == 4.22)\n",
    "assert(interaction_level_df.filter('user_id == 601529').select('user_n_ratings').first()[0] == 27)\n",
    "assert(round(interaction_level_df.filter('user_id == 601529').select('user_avg_years_betwn_review_and_submission').first()[0], 2) == 3.51)\n",
    "assert(interaction_level_df.filter('user_id == 233044').select('user_avg_prep_time_recipes_reviewed').first()[0] == 50.3)\n",
    "assert(interaction_level_df.filter('user_id == 233044').select('user_avg_n_steps_recipes_reviewed').first()[0] == 8.8)\n",
    "assert(interaction_level_df.filter('user_id == 233044').select('user_avg_n_ingredients_recipes_reviewed').first()[0] == 8.2)\n",
    "assert(round(interaction_level_df.filter('user_id == 233044').select('user_avg_total_fat_per_100_cal_recipes_reviewed').first()[0]) == 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7513b134",
   "metadata": {},
   "source": [
    "**More Features:**\n",
    "\n",
    "high_ratings = 5 rating\n",
    "\n",
    "- `user_avg_years_betwn_review_and_submission_high_ratings`\n",
    "- `user_avg_prep_time_recipes_reviewed_high_ratings`\n",
    "- `user_avg_n_steps_recipes_reviewed_high_ratings`\n",
    "- `user_avg_n_ingredients_recipes_reviewed_high_ratings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa15a2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_level_df = (interaction_level_df\n",
    "                        .withColumn(\"ind_5_rating\",\n",
    "                                    F.when(interaction_level_df[\"rating\"] != 5, None)\n",
    "                                     .otherwise(1))\n",
    "                        .withColumn(\"years_since_submission_on_review_date_5_ratings\",\n",
    "                                    F.when(interaction_level_df[\"rating\"] != 5, None)\n",
    "                                     .otherwise(F.col(\"years_since_submission_on_review_date\")))\n",
    "                        .withColumn(\"minutes_5_ratings\",\n",
    "                                    F.when(interaction_level_df[\"rating\"] != 5, None)\n",
    "                                     .otherwise(F.col(\"minutes\")))\n",
    "                        .withColumn(\"n_steps_5_ratings\",\n",
    "                                    F.when(interaction_level_df[\"rating\"] != 5, None)\n",
    "                                     .otherwise(F.col(\"n_steps\")))\n",
    "                        .withColumn(\"n_ingredients_5_ratings\",\n",
    "                                    F.when(interaction_level_df[\"rating\"] != 5, None)\n",
    "                                     .otherwise(F.col(\"n_ingredients\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4daa41ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = Window.partitionBy(\"user_id\")\n",
    "\n",
    "interaction_level_df = (interaction_level_df\n",
    "                        .withColumn(\"user_n_5_ratings\",\n",
    "                                    F.sum(F.col(\"ind_5_rating\")).over(partition))\n",
    "                        .withColumn(\"user_avg_years_betwn_review_and_submission_5_ratings\",\n",
    "                                    F.avg(F.col(\"years_since_submission_on_review_date_5_ratings\")).over(partition))\n",
    "                        .withColumn(\"user_avg_prep_time_recipes_reviewed_5_ratings\",\n",
    "                                    F.avg(F.col(\"minutes_5_ratings\")).over(partition))\n",
    "                        .withColumn(\"user_avg_n_steps_recipes_reviewed_5_ratings\",\n",
    "                                    F.avg(F.col(\"n_steps_5_ratings\")).over(partition))\n",
    "                        .withColumn(\"user_avg_n_ingredients_recipes_reviewed_5_ratings\",\n",
    "                                    F.avg(F.col(\"n_ingredients_5_ratings\")).over(partition)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49be153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nutri_col in nutrition_cols:\n",
    "    interaction_level_df = (interaction_level_df\n",
    "                            .withColumn(\"{}_5_ratings\".format(nutri_col),\n",
    "                                        F.when(interaction_level_df[\"rating\"] != 5, None)\n",
    "                                         .otherwise(F.col(nutri_col))))\n",
    "    interaction_level_df = (interaction_level_df\n",
    "                            .withColumn(\"user_avg_{}_recipes_reviewed_5_ratings\".format(nutri_col),\n",
    "                                        F.avg(F.col(\"{}_5_ratings\".format(nutri_col))).over(partition)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27ec5f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Check - All rows with ratings should have non-null values in corresponding user_avg_5_ratings columns\n",
    "\n",
    "assert(interaction_level_df\n",
    "       .filter(\"rating == 5\")\n",
    "       .filter(interaction_level_df.user_n_5_ratings.isNull() |\n",
    "               interaction_level_df.user_avg_years_betwn_review_and_submission_5_ratings.isNull() |\n",
    "               interaction_level_df.user_avg_prep_time_recipes_reviewed_5_ratings.isNull() |\n",
    "               interaction_level_df.user_avg_n_steps_recipes_reviewed_5_ratings.isNull() |\n",
    "               interaction_level_df.user_avg_n_ingredients_recipes_reviewed_5_ratings.isNull())\n",
    "       .count() == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34bcdbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check values for a given user id\n",
    "\n",
    "assert(interaction_level_df.filter('user_id == 233044').select('user_n_5_ratings').first()[0] == 7)\n",
    "assert(round(interaction_level_df.filter('user_id == 233044').select('user_avg_years_betwn_review_and_submission_5_ratings').first()[0], 2) == 2.24)\n",
    "assert(round(interaction_level_df.filter('user_id == 233044').select('user_avg_prep_time_recipes_reviewed_5_ratings').first()[0]) == 46)\n",
    "assert(round(interaction_level_df.filter('user_id == 233044').select('user_avg_n_steps_recipes_reviewed_5_ratings').first()[0], 2) == 7.29)\n",
    "assert(round(interaction_level_df.filter('user_id == 233044').select('user_avg_n_ingredients_recipes_reviewed_5_ratings').first()[0], 2) == 6.86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b122a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- recipe_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- review: string (nullable = true)\n",
      " |-- review_date: date (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- minutes: integer (nullable = true)\n",
      " |-- contributor_id: integer (nullable = true)\n",
      " |-- submitted: date (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- nutrition: string (nullable = true)\n",
      " |-- n_steps: integer (nullable = true)\n",
      " |-- steps: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- ingredients: string (nullable = true)\n",
      " |-- n_ingredients: integer (nullable = true)\n",
      " |-- calories: float (nullable = true)\n",
      " |-- total_fat_PDV: float (nullable = true)\n",
      " |-- sugar_PDV: float (nullable = true)\n",
      " |-- sodium_PDV: float (nullable = true)\n",
      " |-- protein_PDV: float (nullable = true)\n",
      " |-- saturated_fat_PDV: float (nullable = true)\n",
      " |-- carbohydrates_PDV: float (nullable = true)\n",
      " |-- total_fat_per_100_cal: double (nullable = true)\n",
      " |-- sugar_per_100_cal: double (nullable = true)\n",
      " |-- sodium_per_100_cal: double (nullable = true)\n",
      " |-- protein_per_100_cal: double (nullable = true)\n",
      " |-- saturated_fat_per_100_cal: double (nullable = true)\n",
      " |-- carbohydrates_per_100_cal: double (nullable = true)\n",
      " |-- days_since_submission_on_review_date: integer (nullable = true)\n",
      " |-- months_since_submission_on_review_date: double (nullable = true)\n",
      " |-- years_since_submission_on_review_date: double (nullable = true)\n",
      " |-- years_since_submission_on_review_date_bucket: double (nullable = true)\n",
      " |-- prep_time_bucket: double (nullable = true)\n",
      " |-- n_steps_bucket: double (nullable = true)\n",
      " |-- n_ingredients_bucket: double (nullable = true)\n",
      " |-- calories_bucket: double (nullable = true)\n",
      " |-- total_fat_PDV_bucket: double (nullable = true)\n",
      " |-- sugar_PDV_bucket: double (nullable = true)\n",
      " |-- sodium_PDV_bucket: double (nullable = true)\n",
      " |-- protein_PDV_bucket: double (nullable = true)\n",
      " |-- saturated_fat_PDV_bucket: double (nullable = true)\n",
      " |-- carbohydrates_PDV_bucket: double (nullable = true)\n",
      " |-- total_fat_per_100_cal_bucket: double (nullable = true)\n",
      " |-- sugar_per_100_cal_bucket: double (nullable = true)\n",
      " |-- sodium_per_100_cal_bucket: double (nullable = true)\n",
      " |-- protein_per_100_cal_bucket: double (nullable = true)\n",
      " |-- saturated_fat_per_100_cal_bucket: double (nullable = true)\n",
      " |-- carbohydrates_per_100_cal_bucket: double (nullable = true)\n",
      " |-- user_avg_rating: double (nullable = true)\n",
      " |-- user_n_ratings: long (nullable = false)\n",
      " |-- user_avg_years_betwn_review_and_submission: double (nullable = true)\n",
      " |-- user_avg_prep_time_recipes_reviewed: double (nullable = true)\n",
      " |-- user_avg_n_steps_recipes_reviewed: double (nullable = true)\n",
      " |-- user_avg_n_ingredients_recipes_reviewed: double (nullable = true)\n",
      " |-- user_avg_calories_recipes_reviewed: double (nullable = true)\n",
      " |-- user_avg_total_fat_per_100_cal_recipes_reviewed: double (nullable = true)\n",
      " |-- user_avg_sugar_per_100_cal_recipes_reviewed: double (nullable = true)\n",
      " |-- user_avg_sodium_per_100_cal_recipes_reviewed: double (nullable = true)\n",
      " |-- user_avg_protein_per_100_cal_recipes_reviewed: double (nullable = true)\n",
      " |-- user_avg_saturated_fat_per_100_cal_recipes_reviewed: double (nullable = true)\n",
      " |-- user_avg_carbohydrates_per_100_cal_recipes_reviewed: double (nullable = true)\n",
      " |-- ind_5_rating: integer (nullable = true)\n",
      " |-- years_since_submission_on_review_date_5_ratings: double (nullable = true)\n",
      " |-- minutes_5_ratings: integer (nullable = true)\n",
      " |-- n_steps_5_ratings: integer (nullable = true)\n",
      " |-- n_ingredients_5_ratings: integer (nullable = true)\n",
      " |-- user_n_5_ratings: long (nullable = true)\n",
      " |-- user_avg_years_betwn_review_and_submission_5_ratings: double (nullable = true)\n",
      " |-- user_avg_prep_time_recipes_reviewed_5_ratings: double (nullable = true)\n",
      " |-- user_avg_n_steps_recipes_reviewed_5_ratings: double (nullable = true)\n",
      " |-- user_avg_n_ingredients_recipes_reviewed_5_ratings: double (nullable = true)\n",
      " |-- calories_5_ratings: float (nullable = true)\n",
      " |-- user_avg_calories_recipes_reviewed_5_ratings: double (nullable = true)\n",
      " |-- total_fat_per_100_cal_5_ratings: double (nullable = true)\n",
      " |-- user_avg_total_fat_per_100_cal_recipes_reviewed_5_ratings: double (nullable = true)\n",
      " |-- sugar_per_100_cal_5_ratings: double (nullable = true)\n",
      " |-- user_avg_sugar_per_100_cal_recipes_reviewed_5_ratings: double (nullable = true)\n",
      " |-- sodium_per_100_cal_5_ratings: double (nullable = true)\n",
      " |-- user_avg_sodium_per_100_cal_recipes_reviewed_5_ratings: double (nullable = true)\n",
      " |-- protein_per_100_cal_5_ratings: double (nullable = true)\n",
      " |-- user_avg_protein_per_100_cal_recipes_reviewed_5_ratings: double (nullable = true)\n",
      " |-- saturated_fat_per_100_cal_5_ratings: double (nullable = true)\n",
      " |-- user_avg_saturated_fat_per_100_cal_recipes_reviewed_5_ratings: double (nullable = true)\n",
      " |-- carbohydrates_per_100_cal_5_ratings: double (nullable = true)\n",
      " |-- user_avg_carbohydrates_per_100_cal_recipes_reviewed_5_ratings: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interaction_level_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d947f240",
   "metadata": {},
   "source": [
    "## Tags level EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0537107",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_tag_level_df = interaction_level_df.withColumn('individual_tag',F.explode('tags'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a15d9938",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_ratings_summary = (interaction_tag_level_df\n",
    "                        .groupBy('individual_tag').agg(F.avg('rating').alias('avg_user_rating'),\n",
    "#                                                      F.max('rating').alias('max_user_rating'),\n",
    "#                                                      F.min('rating').alias('min_user_rating'),\n",
    "                                                       F.count('rating').alias('n_user_ratings'),\n",
    "                                                       F.countDistinct('id').alias('n_recipes')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1aea4dfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "interactions, recipes  =  interaction_level_df.count(), interaction_level_df.agg(F.countDistinct('id')).first()[0]\n",
    "\n",
    "tags_ratings_summary = (tags_ratings_summary.withColumn(\"in_percent_recipies\", F.col (\"n_recipes\")/F.lit(recipes))\n",
    "                                            .withColumn(\"in_percent_interactions\", F.col (\"n_user_ratings\")/F.lit(interactions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b73f1b2",
   "metadata": {},
   "source": [
    "#### 1. Top ```n``` most rated tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8969bb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/20 17:43:13 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/12/20 17:43:14 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/12/20 17:43:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/12/20 17:43:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/12/20 17:43:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/12/20 17:43:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+--------------+---------+-------------------+-----------------------+\n",
      "|    individual_tag|  avg_user_rating|n_user_ratings|n_recipes|in_percent_recipies|in_percent_interactions|\n",
      "+------------------+-----------------+--------------+---------+-------------------+-----------------------+\n",
      "|       preparation|4.411904891055459|       1124563|   229451| 0.9952676735692412|     0.9970820691330615|\n",
      "|      time-to-make|4.414410033551223|       1106368|   224231| 0.9726253784559863|     0.9809496619243271|\n",
      "|            course|4.412393373452436|       1073138|   217264| 0.9424052884073184|      0.951486628588452|\n",
      "|           dietary|4.412022680371238|        902278|   164026| 0.7114799038786859|     0.7999953894741695|\n",
      "|   main-ingredient|4.423995977552896|        865145|   169674| 0.7359786936870505|     0.7670718018466929|\n",
      "|              easy|4.418360735722059|        631271|   125815| 0.5457357010870036|     0.5597098560629301|\n",
      "|          occasion|4.414493748831331|        620364|   113508| 0.4923528033937417|     0.5500392781335173|\n",
      "|         equipment|4.415504436873788|        497535|    69937| 0.3033590408689089|     0.4411342248198792|\n",
      "|           cuisine|4.416950785418921|        479553|    90715|   0.39348578567029|    0.42519067184227743|\n",
      "|  low-in-something|4.414680695215076|        446423|    85318|0.37007573457330983|     0.3958163024646807|\n",
      "|         main-dish|4.395939165475108|        384650|    71602| 0.3105811522412402|      0.341045915517434|\n",
      "|60-minutes-or-less|4.405608852652683|        343671|    69990| 0.3035889339035837|    0.30471231205457444|\n",
      "|number-of-servings|4.407178035329854|        339090|    58440| 0.2534896027621865|     0.3006506161258461|\n",
      "|              meat|4.408212515024038|        319488|    55818|0.24211640395242515|     0.2832707070241361|\n",
      "|        taste-mood|4.412416637754905|        311292|    52092|0.22595448985434324|     0.2760038090036476|\n",
      "|    north-american|4.413228878128546|        283758|    48213|0.20912892227880386|     0.2515910747313039|\n",
      "|30-minutes-or-less|4.426849710766375|        267258|    55077|0.23890223907140565|     0.2369615216153864|\n",
      "|        vegetables| 4.45455314469399|        260073|    53613| 0.2325519861890675|    0.23059101621309142|\n",
      "|              oven|4.417788711548462|        249990|    30801| 0.1336025539814871|    0.22165102929989167|\n",
      "|   4-hours-or-less|4.383290721317416|        248365|    49496| 0.2146940687597054|    0.22021023997786948|\n",
      "+------------------+-----------------+--------------+---------+-------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tags_ratings_summary.sort(F.col(\"n_user_ratings\").desc()).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d3b60e",
   "metadata": {},
   "source": [
    "Drop tags present in majority of recipes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8601fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_ratings_summary = tags_ratings_summary.filter(tags_ratings_summary.in_percent_interactions < 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d7c6535",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_most_frequent_tags = tags_ratings_summary.sort(F.col(\"n_user_ratings\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a68f45de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0.0: 8.86639582782878e-07,\n",
       " 0.01: 8.86639582782878e-07,\n",
       " 0.25: 0.00035908903102706556,\n",
       " 0.5: 0.003420655510376343,\n",
       " 0.75: 0.018878329996613038,\n",
       " 0.8: 0.027476074030858604,\n",
       " 0.85: 0.044293853637084234,\n",
       " 0.9: 0.08071080122072538,\n",
       " 0.95: 0.1640762013523027,\n",
       " 0.99: 0.341045915517434,\n",
       " 1.0: 0.5597098560629301}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_quantiles(df = top_most_frequent_tags , \n",
    "              col_name = 'in_percent_interactions', \n",
    "              quantiles_list = [0.01,0.25,0.5, 0.75,0.8,0.85,0.9,0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4bc86bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep tags appearing in the top 5 percentile \n",
    "top_most_frequent_tags = top_most_frequent_tags.filter(\"in_percent_interactions > 0.16\")\n",
    "\n",
    "top_most_frequent_tags.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a80d5598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_frequent_tags_list = [data[0] for data in top_most_frequent_tags.select('individual_tag').collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0323df86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added column: has_tag_easy\n",
      "added column: has_tag_occasion\n",
      "added column: has_tag_equipment\n",
      "added column: has_tag_cuisine\n",
      "added column: has_tag_low-in-something\n",
      "added column: has_tag_main-dish\n",
      "added column: has_tag_60-minutes-or-less\n",
      "added column: has_tag_number-of-servings\n",
      "added column: has_tag_meat\n",
      "added column: has_tag_taste-mood\n",
      "added column: has_tag_north-american\n",
      "added column: has_tag_30-minutes-or-less\n",
      "added column: has_tag_vegetables\n",
      "added column: has_tag_oven\n",
      "added column: has_tag_4-hours-or-less\n",
      "added column: has_tag_low-carb\n",
      "added column: has_tag_holiday-event\n",
      "added column: has_tag_desserts\n",
      "added column: has_tag_healthy\n",
      "added column: has_tag_dinner-party\n",
      "added column: has_tag_15-minutes-or-less\n",
      "added column: has_tag_low-sodium\n",
      "added column: has_tag_american\n",
      "added column: has_tag_beginner-cook\n",
      "added column: has_tag_low-cholesterol\n",
      "added column: has_tag_low-calorie\n",
      "added column: has_tag_inexpensive\n",
      "added column: has_tag_comfort-food\n",
      "added column: has_tag_kid-friendly\n"
     ]
    }
   ],
   "source": [
    "interaction_level_df = add_OHE_columns (interaction_level_df, top_frequent_tags_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33744553",
   "metadata": {},
   "source": [
    "#### 2.  Bottom ```n``` least rated tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b02c0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/20 17:44:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/12/20 17:44:03 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/12/20 17:44:12 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/12/20 17:44:12 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/12/20 17:44:12 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/12/20 17:44:12 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+--------------+---------+-------------------+-----------------------+\n",
      "|      individual_tag|avg_user_rating|n_user_ratings|n_recipes|in_percent_recipies|in_percent_interactions|\n",
      "+--------------------+---------------+--------------+---------+-------------------+-----------------------+\n",
      "|      desserts-fruit|            5.0|             1|        1| 4.3376044278266E-6|    8.86639582782878E-7|\n",
      "|         beef-sauces|            5.0|             1|        1| 4.3376044278266E-6|    8.86639582782878E-7|\n",
      "|        snacks-sweet|            4.0|             1|        1| 4.3376044278266E-6|    8.86639582782878E-7|\n",
      "|roast-beef-comfor...|            5.0|             1|        1| 4.3376044278266E-6|    8.86639582782878E-7|\n",
      "|       mushroom-soup|            4.0|             1|        1| 4.3376044278266E-6|    8.86639582782878E-7|\n",
      "+--------------------+---------------+--------------+---------+-------------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tags_ratings_summary.sort(F.col(\"n_user_ratings\").asc()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28edd839",
   "metadata": {},
   "source": [
    "The above tags are present in 1 recipe in over two hundred thousand. The features we create based on these tags will not teach the model new information. If these tags were one hot encoded, the entire column would be filled with zeros, and only a few rows will have 1s. One hot encoding of these tags is not a good idea. If you come up with an encoding that captures the rarity of these tags, only then can you add these tags to the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bacac2",
   "metadata": {},
   "source": [
    "#### 3. Top ```n``` rated tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f4391c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/20 17:44:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/12/20 17:44:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/12/20 17:44:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/12/20 17:44:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/12/20 17:44:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/12/20 17:44:32 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+--------------+---------+-------------------+-----------------------+\n",
      "|      individual_tag|avg_user_rating|n_user_ratings|n_recipes|in_percent_recipies|in_percent_interactions|\n",
      "+--------------------+---------------+--------------+---------+-------------------+-----------------------+\n",
      "|   beans-side-dishes|            5.0|             2|        2| 8.6752088556532E-6|   1.773279165565756E-6|\n",
      "|       desserts-easy|            5.0|             1|        1| 4.3376044278266E-6|    8.86639582782878E-7|\n",
      "|         beef-sauces|            5.0|             1|        1| 4.3376044278266E-6|    8.86639582782878E-7|\n",
      "|             cabbage|            5.0|             1|        1| 4.3376044278266E-6|    8.86639582782878E-7|\n",
      "|heirloom-historic...|            5.0|             3|        2| 8.6752088556532E-6|   2.659918748348633...|\n",
      "+--------------------+---------------+--------------+---------+-------------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tags_ratings_summary.sort(F.col(\"avg_user_rating\").desc()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba743fa",
   "metadata": {},
   "source": [
    "Top rated tags have low number of ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50c62424",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0.0: 1,\n",
       " 0.01: 1.0,\n",
       " 0.05: 1.0,\n",
       " 0.1: 12.0,\n",
       " 0.15: 99.0,\n",
       " 0.2: 187.0,\n",
       " 0.25: 405.0,\n",
       " 0.5: 3858.0,\n",
       " 0.75: 21292.0,\n",
       " 0.99: 384650.0,\n",
       " 1.0: 631271}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_quantiles (tags_ratings_summary, \"n_user_ratings\", quantiles_list = [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.5, 0.75, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eec928b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_ratings_summary = tags_ratings_summary.filter(tags_ratings_summary.n_user_ratings > 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f52df5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_rated_tags_df = tags_ratings_summary.sort(F.col(\"avg_user_rating\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "558d9eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0.0: 3.6742424242424243,\n",
       " 0.01: 3.962536023054755,\n",
       " 0.25: 4.343020485945688,\n",
       " 0.5: 4.4036076010417675,\n",
       " 0.75: 4.451298701298701,\n",
       " 0.8: 4.461002965063813,\n",
       " 0.85: 4.483433874709977,\n",
       " 0.9: 4.503597122302159,\n",
       " 0.95: 4.536693785121194,\n",
       " 0.99: 4.609756097560975,\n",
       " 1.0: 4.822727272727272}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_quantiles(df = top_rated_tags_df , \n",
    "              col_name = 'avg_user_rating', \n",
    "              quantiles_list = [0.01,0.25,0.5, 0.75,0.8,0.85,0.9,0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62a0ca52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep tags above 95 percentile\n",
    "top_rated_tags_df = top_rated_tags_df.filter(\"avg_user_rating > 4.53\")\n",
    "\n",
    "top_rated_tags_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06ccccb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_rated_tags_list = [data[0] for data in top_rated_tags_df.select('individual_tag').collect()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfe9edf",
   "metadata": {},
   "source": [
    "Check if any of the current tags have been added earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aaafc25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(top_frequent_tags_list) & set(top_rated_tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31c5a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_added_columns_set = set(top_frequent_tags_list).union(set(top_rated_tags_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5693caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added column: has_tag_ragu-recipe-contest\n",
      "added column: has_tag_simply-potatoes2\n",
      "added column: has_tag_non-alcoholic\n",
      "added column: has_tag_a1-sauce\n",
      "added column: has_tag_labor-day\n",
      "added column: has_tag_punch\n",
      "added column: has_tag_lettuces\n",
      "added column: has_tag_cocktails\n",
      "added column: has_tag_mashed-potatoes\n",
      "added column: has_tag_smoothies\n",
      "added column: has_tag_turkey-burgers\n",
      "added column: has_tag_avocado\n",
      "added column: has_tag_beverages\n",
      "added column: has_tag_asparagus\n",
      "added column: has_tag_mango\n",
      "added column: has_tag_memorial-day\n",
      "added column: has_tag_shakes\n",
      "added column: has_tag_salsas\n",
      "added column: has_tag_omelets-and-frittatas\n",
      "added column: has_tag_strawberries\n",
      "added column: has_tag_greek\n",
      "added column: has_tag_salads\n",
      "added column: has_tag_barbecue\n",
      "added column: has_tag_australian\n",
      "added column: has_tag_grilling\n",
      "added column: has_tag_polynesian\n"
     ]
    }
   ],
   "source": [
    "interaction_level_df = add_OHE_columns (interaction_level_df, top_rated_tags_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de06488a",
   "metadata": {},
   "source": [
    "#### 3. Bottom ```n``` rated tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5f3abff",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_rated_tags_df = tags_ratings_summary.sort(F.col(\"avg_user_rating\").asc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d21ffd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0.0: 3.6742424242424243,\n",
       " 0.01: 3.962536023054755,\n",
       " 0.02: 4.054406964091403,\n",
       " 0.03: 4.096385542168675,\n",
       " 0.04: 4.126760563380282,\n",
       " 0.05: 4.171974522292993,\n",
       " 0.1: 4.238095238095238,\n",
       " 0.15: 4.303225806451613,\n",
       " 0.2: 4.325726141078838,\n",
       " 0.25: 4.343020485945688,\n",
       " 0.5: 4.4036076010417675,\n",
       " 0.75: 4.451298701298701,\n",
       " 0.99: 4.609756097560975,\n",
       " 1.0: 4.822727272727272}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_quantiles (bottom_rated_tags_df, \"avg_user_rating\", quantiles_list = [0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25, 0.5, 0.75, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2166012b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 173:==========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "bottom_rated_tags_df = bottom_rated_tags_df.filter(\"avg_user_rating < 4.00\")\n",
    "\n",
    "bottom_rated_tags_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad52943b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "bottom_rated_tags_list = [data[0] for data in bottom_rated_tags_df.select('individual_tag').collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "06b5caf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_added_columns_set & set(bottom_rated_tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b044ac62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added column: has_tag_pressure-canning\n",
      "added column: has_tag_honduran\n",
      "added column: has_tag_unprocessed-freezer\n",
      "added column: has_tag_birthday\n",
      "added column: has_tag_jellies\n",
      "added column: has_tag_water-bath\n"
     ]
    }
   ],
   "source": [
    "interaction_level_df =  add_OHE_columns(interaction_level_df, bottom_rated_tags_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedadf63",
   "metadata": {},
   "source": [
    "## Final DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5dffa017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(interaction_level_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c878b1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/20 17:46:07 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "interaction_level_df.write.mode('overwrite').parquet('interaction_level_df_ModelReady.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b088cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1928b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
